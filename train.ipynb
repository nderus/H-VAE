{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoders import EncoderResNet18, EncoderResNet34, encoderCNN\n",
    "from decoders import DecoderResNet18, DecoderResNet34, decoderCNN\n",
    "from datasets import data_loader\n",
    "from embedding import embedding\n",
    "from reconstructions import reconstructions\n",
    "from generations import Generations\n",
    "from activations import VisualizeActivations\n",
    "from src.CVAE import CVAE\n",
    "\n",
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: this should be passed as arguments\n",
    "dataset_name = 'histo'\n",
    "model_name = 'CVAE_resnet'\n",
    "kl_coefficient = 0.002\n",
    "encoded_dim = 640\n",
    "learning_rate = 0.0001 \n",
    "epoch_count = 100\n",
    "batch_size = 100\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "if dataset_name == 'experimental':\n",
    "    #TO DO: move datasets in the repo and change root_folder\n",
    "\n",
    "    train_ds, val_ds, input_shape, category_count, labels = data_loader(name=dataset_name, root_folder='/home/PERSONALE/nicolas.derus2/HistoDL/datasets/')\n",
    "else:\n",
    "    #TO DO: move datasets in the repo and change root_folder\n",
    "\n",
    "    train_x, test_x, val_x, train_y, test_y, val_y, train_y_one_hot, test_y_one_hot, val_y_one_hot, input_shape, category_count, labels = data_loader(name=dataset_name,\n",
    "                                                                                                                                        root_folder='/home/PERSONALE/nicolas.derus2/HistoDL/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wandb.init(project=\"HistoDL\", entity=\"nrderus\",\n",
    "#   config = {\n",
    "#   \"dataset\": dataset_name,\n",
    "#   \"model\": model_name,\n",
    "#   \"encoded_dim\": encoded_dim,\n",
    "#   \"kl_coefficient\": kl_coefficient,\n",
    "#   \"learning_rate\": learning_rate,\n",
    "#   \"epochs\": epoch_count,\n",
    "#   \"batch_size\": batch_size,\n",
    "#   \"patience\": patience,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 12:57:18.543707: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 64, 64, 5)]  0           []                               \n",
      "                                                                                                  \n",
      " layer0 (Sequential)            (None, 32, 32, 64)   16000       ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " layer1 (Sequential)            (None, 32, 32, 64)   148736      ['layer0[0][0]']                 \n",
      "                                                                                                  \n",
      " layer2 (Sequential)            (None, 16, 16, 128)  527488      ['layer1[0][0]']                 \n",
      "                                                                                                  \n",
      " layer3 (Sequential)            (None, 8, 8, 256)    2103552     ['layer2[0][0]']                 \n",
      "                                                                                                  \n",
      " layer4 (Sequential)            (None, 4, 4, 512)    8401408     ['layer3[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['layer4[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder_bottleneck (Dense)     (None, 1280)         10487040    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 640)          819840      ['encoder_bottleneck[0][0]']     \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 640)          819840      ['encoder_bottleneck[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,323,904\n",
      "Trainable params: 23,314,304\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if 'resnet' in model_name:\n",
    "    encoder = EncoderResNet18(encoded_dim = encoded_dim)\n",
    "    encoder = encoder.model(input_shape=(input_shape[0], input_shape[1], input_shape[2] + category_count))\n",
    "else:\n",
    "    encoder = encoderCNN(input_shape, category_count, encoded_dim)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 642)]             0         \n",
      "                                                                 \n",
      " pre_reshape (Dense)         (None, 8192)              5267456   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " layer5 (Sequential)         (None, 4, 4, 512)         9445376   \n",
      "                                                                 \n",
      " layer6 (Sequential)         (None, 8, 8, 256)         3085312   \n",
      "                                                                 \n",
      " layer7 (Sequential)         (None, 16, 16, 128)       772608    \n",
      "                                                                 \n",
      " layer8 (Sequential)         (None, 32, 32, 64)        268032    \n",
      "                                                                 \n",
      " layer9 (Sequential)         (None, 32, 32, 64)        200960    \n",
      "                                                                 \n",
      " outputs (Conv2DTranspose)   (None, 64, 64, 3)         195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,039,939\n",
      "Trainable params: 19,030,979\n",
      "Non-trainable params: 8,960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if 'resnet' in model_name:\n",
    "    decoder = DecoderResNet18( encoded_dim = encoded_dim)\n",
    "    decoder = decoder.model(input_shape=(encoded_dim + category_count,))\n",
    "else:\n",
    "    decoder = decoderCNN(input_shape, category_count, encoded_dim)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    # This is the TPU initialization code that has to be at the beginning.\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    with strategy.scope():\n",
    "        cvae = CVAE(encoder, decoder, kl_coefficient, input_shape, category_count)\n",
    "        cvae.built = True\n",
    "        cvae_input = cvae.encoder.input[0]\n",
    "        cvae_output = cvae.decoder.output\n",
    "        mu = cvae.encoder.get_layer('mu').output\n",
    "        log_var = cvae.encoder.get_layer('log_var').output\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        cvae.compile(optimizer = opt, run_eagerly=False)\n",
    "except:\n",
    "    cvae = CVAE(encoder, decoder, kl_coefficient, input_shape, category_count)\n",
    "    cvae.built = True\n",
    "    cvae_input = cvae.encoder.input[0]\n",
    "    cvae_output = cvae.decoder.output\n",
    "    mu = cvae.encoder.get_layer('mu').output\n",
    "    log_var = cvae.encoder.get_layer('log_var').output\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    cvae.compile(optimizer = opt, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "             patience=patience, restore_best_weights=False)\n",
    "\n",
    "history = cvae.fit([train_x, train_y_one_hot],\n",
    "                   validation_data = ([val_x, val_y_one_hot],None),\n",
    "                   epochs = epoch_count,\n",
    "                   batch_size = batch_size,\n",
    "                   callbacks=[early_stop, WandbCallback(save_model = False) ]) #save_weights_only -> ValueError: Unable to create dataset (name already exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_label_train, train_input = cvae.conditional_input([train_x, train_y_one_hot])\n",
    "_, input_label_test, test_input = cvae.conditional_input([test_x, test_y_one_hot])\n",
    "_, input_label_val, val_input = cvae.conditional_input([val_x, val_y_one_hot])\n",
    "\n",
    "train_x_mean, train_log_var = cvae.encoder.predict(train_input)\n",
    "test_x_mean, test_log_var = cvae.encoder.predict(test_input)\n",
    "val_x_mean, val_log_var = cvae.encoder.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding(encoded_dim, category_count, train_x_mean, test_x_mean, val_x_mean, train_y, test_y, val_y, train_log_var, test_log_var, val_log_var, labels, xy_lim = 80, quantity = 5000, avg_latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions(cvae, train_x, train_y, train_x_mean, train_log_var, input_label_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generations(cvae, encoded_dim, category_count, input_shape, labels)\n",
    "generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activations_encoder = VisualizeActivations(cvae, cvae.encoder, test_x, test_y_one_hot)\n",
    "activations_decoder = VisualizeActivations(cvae, cvae.decoder, test_x, test_y_one_hot)\n",
    "activations_encoder()\n",
    "activations_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish(exit_code=0, quiet = True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('H-VAE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f1607b5c7637eeb63c336da9ec51a12a91ceb8ce0c928f22804c46ad3bcc7ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
