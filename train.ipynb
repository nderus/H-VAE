{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoders import EncoderResNet18, EncoderResNet34, EncoderResNet50, encoderCNN, EncoderMixNet18\n",
    "from decoders import DecoderResNet18, DecoderResNet34, DecoderResNet50, decoderCNN\n",
    "from datasets import data_loader\n",
    "from embeddings import embedding\n",
    "from reconstructions import reconstructions\n",
    "from generations import Generations\n",
    "from activations import VisualizeActivations\n",
    "from gradcam import GradCam\n",
    "from src.CVAE import CVAE\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(embeddings)\n",
    "# from embeddings import embedding\n",
    "\n",
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: this should be passed as arguments\n",
    "dataset_name = 'mnist'\n",
    "model_name = 'CVAE'\n",
    "kl_coefficient = 1\n",
    "encoded_dim = 2\n",
    "learning_rate = 0.0001 \n",
    "epoch_count = 1\n",
    "batch_size = 100\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'experimental':\n",
    "    #TO DO: move datasets in the repo and change root_folder\n",
    "\n",
    "    train_ds, val_ds, input_shape, category_count, labels = data_loader(name=dataset_name, root_folder='/home/PERSONALE/nicolas.derus2/HistoDL/datasets/')\n",
    "else:\n",
    "    #TO DO: move datasets in the repo and change root_folder\n",
    "\n",
    "    train_x, test_x, val_x, train_y, test_y, val_y, train_y_one_hot, test_y_one_hot, val_y_one_hot, input_shape, category_count, labels = data_loader(name=dataset_name,\n",
    "                                                                                                                                        root_folder='/home/PERSONALE/nicolas.derus2/HistoDL/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"train.ipynb\"\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"train.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnrderus\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/PERSONALE/nicolas.derus2/H-VAE/wandb/run-20220730_191114-2uwu0dfx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nrderus/H-VAE/runs/2uwu0dfx\" target=\"_blank\">denim-aardvark-151</a></strong> to <a href=\"https://wandb.ai/nrderus/H-VAE\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nrderus/H-VAE/runs/2uwu0dfx?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8712192970>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.init(project=\"H-VAE\", entity=\"nrderus\",\n",
    "  config = {\n",
    "  \"dataset\": dataset_name,\n",
    "  \"model\": model_name,\n",
    "  \"encoded_dim\": encoded_dim,\n",
    "  \"kl_coefficient\": kl_coefficient,\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epoch_count,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"patience\": patience,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 28, 28, 11)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 28, 28, 16)   1600        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 28, 28, 16)   2320        ['block1_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 16)  64          ['block1_conv2[0][0]']           \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 28, 28, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 28, 28, 32)   4640        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 28, 28, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 28, 32)  128         ['block2_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 28, 28, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " S4 (MaxPooling2D)              (None, 14, 14, 32)   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 14, 14, 64)   18496       ['S4[0][0]']                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 14, 14, 64)   36928       ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 14, 14, 64)  256         ['block3_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 14, 14, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 12544)        0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            25090       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 2)            6           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 2)            6           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 98,782\n",
      "Trainable params: 98,558\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 19:11:19.922302: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "if 'resnet' in model_name:\n",
    "    encoder = EncoderResNet18(encoded_dim = encoded_dim)\n",
    "    encoder = encoder.model(input_shape=(input_shape[0], input_shape[1], input_shape[2] + category_count))\n",
    "\n",
    "else:\n",
    "    encoder = encoderCNN(input_shape, category_count, encoded_dim,  regularizer=regularizers.L2(.001))\n",
    "    #encoder = EncoderMixNet18(encoded_dim = encoded_dim)\n",
    "    #encoder = encoder.model(input_shape=(input_shape[0], input_shape[1], input_shape[2] + category_count))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 28, 28, 11)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 28, 28, 16)   1600        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 28, 28, 16)   2320        ['block1_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 16)  64          ['block1_conv2[0][0]']           \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 28, 28, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 28, 28, 32)   4640        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 28, 28, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 28, 32)  128         ['block2_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 28, 28, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " S4 (MaxPooling2D)              (None, 14, 14, 32)   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 14, 14, 64)   18496       ['S4[0][0]']                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 14, 14, 64)   36928       ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 14, 14, 64)  256         ['block3_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 14, 14, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 12544)        0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            25090       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 2)            6           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 2)            6           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 98,782\n",
      "Trainable params: 98,558\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 12)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12544)             163072    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " up_block4_conv1 (Conv2DTran  (None, 14, 14, 64)       36928     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block4_conv2 (Conv2DTran  (None, 14, 14, 64)       36928     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " up_block5_conv1 (Conv2DTran  (None, 14, 14, 32)       18464     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv2 (Conv2DTran  (None, 14, 14, 32)       9248      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 28, 28, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " up_block6_conv1 (Conv2DTran  (None, 28, 28, 16)       4624      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block6_conv2 (Conv2DTran  (None, 28, 28, 16)       2320      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 28, 28, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 28, 28, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 28, 28, 1)        145       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,433\n",
      "Trainable params: 272,081\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if 'resnet' in model_name:\n",
    "    decoder = DecoderResNet18( encoded_dim = encoded_dim, final_stride = 2)\n",
    "    decoder = decoder.model(input_shape=(encoded_dim + category_count,))\n",
    "else:\n",
    "    decoder = decoderCNN(input_shape, category_count, encoded_dim, final_stride = 1, regularizer=regularizers.L2(.001))\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    # This is the TPU initialization code that has to be at the beginning.\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    with strategy.scope():\n",
    "        cvae = CVAE(encoder, decoder, kl_coefficient, input_shape, category_count)\n",
    "        cvae.built = True\n",
    "        cvae_input = cvae.encoder.input[0]\n",
    "        cvae_output = cvae.decoder.output\n",
    "        mu = cvae.encoder.get_layer('mu').output\n",
    "        log_var = cvae.encoder.get_layer('log_var').output\n",
    "\n",
    "        # def scheduler(epoch, lr):\n",
    "        #     if epoch < 30:\n",
    "        #         return lr\n",
    "        #     else:\n",
    "        #         return lr * tf.math.exp(-0.1)\n",
    "            \n",
    "        opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "        cvae.compile(optimizer = opt, run_eagerly=False)\n",
    "except:\n",
    "    \n",
    "    cvae = CVAE(encoder, decoder, kl_coefficient, input_shape, category_count)\n",
    "    cvae.built = True\n",
    "    cvae_input = cvae.encoder.input[0]\n",
    "    cvae_output = cvae.decoder.output\n",
    "    mu = cvae.encoder.get_layer('mu').output\n",
    "    log_var = cvae.encoder.get_layer('log_var').output\n",
    "\n",
    "    # def scheduler(epoch, lr):\n",
    "    #     if epoch < 30:\n",
    "    #         return lr\n",
    "    #     else:\n",
    "    #         return lr * tf.math.exp(-0.1)\n",
    "    opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    cvae.compile(optimizer = opt, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to compute FLOPs for this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 65s 126ms/step - loss: 55.9561 - reconstruction_loss: 54.9031 - kl_loss: 1.0530 - loss_no_weights: 55.9561 - val_loss: 37.4589 - val_reconstruction_loss: 35.3893 - val_kl_loss: 2.0696 - val_loss_no_weights: 37.4589 - _timestamp: 1659201145.0000 - _runtime: 71.0000\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "             patience=patience, restore_best_weights=False)\n",
    "\n",
    "\n",
    "# lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
    "#     lambda epoch: learning_rate * learning_rate_exp_decay**epoch,\n",
    "#     verbose=True)\n",
    "\n",
    "history = cvae.fit([train_x, train_y_one_hot],\n",
    "                   validation_data = ([val_x, val_y_one_hot],None),\n",
    "                   epochs = epoch_count,\n",
    "                   batch_size = batch_size,\n",
    "                   callbacks=[early_stop, WandbCallback(save_model = False) ]) #save_weights_only -> ValueError: Unable to create dataset (name already exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(cvae.encoder, 'cvae_encoder')\n",
    "# tf.saved_model.save(cvae.decoder, 'cvae_decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_label_train, train_input = cvae.conditional_input([train_x[:1000], train_y_one_hot[:1000]])\n",
    "_, input_label_test, test_input = cvae.conditional_input([test_x[:1000], test_y_one_hot[:1000]])\n",
    "_, input_label_val, val_input = cvae.conditional_input([val_x[:1000], val_y_one_hot[:1000]])\n",
    "\n",
    "train_x_mean, train_log_var = cvae.encoder.predict(train_input)\n",
    "test_x_mean, test_log_var = cvae.encoder.predict(test_input)\n",
    "val_x_mean, val_log_var = cvae.encoder.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CVAE import SecondStage\n",
    "from encoders import encoder2\n",
    "from decoders import decoder2\n",
    "z_cond = cvae.sampling(train_x_mean, train_log_var,train_y_one_hot[:1000])\n",
    "encoder_2 = encoder2(encoded_dim, category_count, second_dim=1024, second_depth=3 )\n",
    "decoder_2 = decoder2(encoded_dim, category_count, second_dim=1024, second_depth=3 )\n",
    "cvae2 = SecondStage(encoder_2, decoder_2, category_count, batch_size)\n",
    "opt2 = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "cvae2.compile(optimizer = opt2, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/home/PERSONALE/nicolas.derus2/miniconda3/envs/H-VAE/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/PERSONALE/nicolas.derus2/H-VAE/src/CVAE.py\", line 328, in train_step  *\n        kl_loss2 = tf.reduce_sum(tf.square(mu_u) + tf.square(sd_u) - 2 * logsd_u - 1) / 2.0 / float(self.batch_size)\n\n    AttributeError: 'SecondStage' object has no attribute 'batch_size'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/H-VAE/train.ipynb Cella 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/H-VAE/train.ipynb#ch0000030vscode-remote?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m cvae2\u001b[39m.\u001b[39;49mfit([z_cond, train_y_one_hot[:\u001b[39m1000\u001b[39;49m]],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/H-VAE/train.ipynb#ch0000030vscode-remote?line=1'>2</a>\u001b[0m                     validation_data \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/H-VAE/train.ipynb#ch0000030vscode-remote?line=2'>3</a>\u001b[0m                    epochs \u001b[39m=\u001b[39;49m epoch_count,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/H-VAE/train.ipynb#ch0000030vscode-remote?line=3'>4</a>\u001b[0m                    batch_size \u001b[39m=\u001b[39;49m batch_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/H-VAE/lib/python3.9/site-packages/wandb/integration/keras/keras.py:173\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    172\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/H-VAE/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/H-VAE/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/home/PERSONALE/nicolas.derus2/miniconda3/envs/H-VAE/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/PERSONALE/nicolas.derus2/H-VAE/src/CVAE.py\", line 328, in train_step  *\n        kl_loss2 = tf.reduce_sum(tf.square(mu_u) + tf.square(sd_u) - 2 * logsd_u - 1) / 2.0 / float(self.batch_size)\n\n    AttributeError: 'SecondStage' object has no attribute 'batch_size'\n"
     ]
    }
   ],
   "source": [
    "history = cvae2.fit([z_cond, train_y_one_hot[:1000]],\n",
    "                    validation_data = None,\n",
    "                   epochs = epoch_count,\n",
    "                   batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding(encoded_dim, category_count, train_x_mean, test_x_mean, val_x_mean, train_y, test_y, val_y, train_log_var, test_log_var, val_log_var, labels, quantity = 1000, avg_latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions(cvae, train_x, train_y, train_x_mean, train_log_var, input_label_train, labels, set = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions(cvae, test_x, test_y, test_x_mean, test_log_var, input_label_test, labels, set = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generations(cvae, encoded_dim, category_count, input_shape, labels)\n",
    "generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activations_encoder = VisualizeActivations(cvae, cvae.encoder, test_x, test_y_one_hot)\n",
    "activations_decoder = VisualizeActivations(cvae, cvae.decoder, test_x, test_y_one_hot)\n",
    "activations_encoder()\n",
    "activations_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'resnet' in model_name:\n",
    "    target_layer = \"layer4\"\n",
    "else:\n",
    "    target_layer = \"block3_conv2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = GradCam(cvae, test_x, test_y_one_hot, HQ = True, target_layer = target_layer)\n",
    "gc.gradcam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.guided_gradcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish(exit_code=0, quiet = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('H-VAE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f1607b5c7637eeb63c336da9ec51a12a91ceb8ce0c928f22804c46ad3bcc7ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
